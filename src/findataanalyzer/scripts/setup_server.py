#!/usr/bin/env python
"""Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÙˆØ± Ù…Ø­Ø§Ø³Ø¨Ø§ØªÛŒ.

Ø§ÛŒÙ† Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ù…Ø­ÛŒØ· Ø§Ø¬Ø±Ø§ÛŒÛŒ Ø³ÛŒØ³ØªÙ… Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ø±Ø¯Ù‡ Ùˆ Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø±Ø§ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
"""

import os
import sys
import argparse
import logging
import subprocess
import platform
from pathlib import Path
import yaml
import shutil
import time

# ØªÙ†Ø¸ÛŒÙ… Ù…Ø³ÛŒØ± Ø¨Ø±Ø§ÛŒ ÙˆØ§Ø±Ø¯Ø³Ø§Ø²ÛŒ Ù…Ø§Ú˜ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from findataanalyzer.utils.config import ConfigManager
from findataanalyzer.utils.logger import LogManager


def parse_args():
    """ØªØ¬Ø²ÛŒÙ‡ Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ø®Ø· ÙØ±Ù…Ø§Ù†."""
    parser = argparse.ArgumentParser(description="Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÙˆØ± Ù…Ø­Ø§Ø³Ø¨Ø§ØªÛŒ")
    parser.add_argument(
        "--config", type=str, default="configs/settings.yaml",
        help="Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ ØªÙ†Ø¸ÛŒÙ…Ø§Øª"
    )
    parser.add_argument(
        "--gpu", action="store_true", default=False,
        help="ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² GPU"
    )
    parser.add_argument(
        "--env", type=str, choices=["dev", "prod", "test"], default="dev",
        help="Ù…Ø­ÛŒØ· Ø§Ø¬Ø±Ø§ÛŒÛŒ (dev/prod/test)"
    )
    parser.add_argument(
        "--setup-db", action="store_true", default=False,
        help="Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡"
    )
    parser.add_argument(
        "--setup-dirs", action="store_true", default=False,
        help="Ø§ÛŒØ¬Ø§Ø¯ Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒâ€ŒÙ‡Ø§"
    )
    parser.add_argument(
        "--install-deps", action="store_true", default=False,
        help="Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ"
    )
    return parser.parse_args()


def check_gpu_support():
    """Ø¨Ø±Ø±Ø³ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² GPU."""
    print("Ø¨Ø±Ø±Ø³ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² GPU...")
    
    # Ø¨Ø±Ø±Ø³ÛŒ TensorFlow Ø¨Ø§ CUDA
    try:
        import tensorflow as tf
        gpus = tf.config.experimental.list_physical_devices('GPU')
        if gpus:
            print(f"âœ… TensorFlow Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ GPU Ù¾ÛŒØ¯Ø§ Ø´Ø¯ (Ù†Ø³Ø®Ù‡: {tf.__version__})")
            print(f"  - Ø¯Ø³ØªÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡: {len(gpus)}")
            for i, gpu in enumerate(gpus):
                print(f"  - {i}: {gpu.name}")
            return True
        else:
            print("âŒ TensorFlow Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ GPU Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯")
    except ImportError:
        print("âŒ TensorFlow Ù†ØµØ¨ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª")
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ GPU: {e}")
    
    return False


def setup_directories(config):
    """Ø§ÛŒØ¬Ø§Ø¯ Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒâ€ŒÙ‡Ø§."""
    print("Ø§ÛŒØ¬Ø§Ø¯ Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒâ€ŒÙ‡Ø§...")
    
    # Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ
    directories = [
        config.get("data_pipeline.raw_data_dir", "data/raw"),
        config.get("data_pipeline.processed_data_dir", "data/processed"),
        config.get("data_pipeline.cache_dir", "data/cache"),
        config.get("experiment_tracking.experiments_dir", "experiments"),
        config.get("experiment_tracking.metrics_dir", "experiments/metrics"),
        config.get("experiment_tracking.checkpoints_dir", "experiments/checkpoints"),
        config.get("experiment_tracking.tensorboard_dir", "experiments/tensorboard"),
        "logs",
        "configs"
    ]
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒâ€ŒÙ‡Ø§
    for directory in directories:
        path = Path(directory)
        path.mkdir(parents=True, exist_ok=True)
        print(f"âœ… Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒ {path} Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯")


def setup_database(config):
    """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡."""
    print("Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡...")
    
    db_url = config.get("database.url", "sqlite:///data/findataanalyzer.db")
    
    if db_url.startswith("sqlite"):
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ SQLite
        import re
        match = re.search(r"sqlite:///(.+)", db_url)
        if match:
            db_path = match.group(1)
            db_dir = os.path.dirname(db_path)
            
            # Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒ
            Path(db_dir).mkdir(parents=True, exist_ok=True)
            print(f"âœ… Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¯Ø± {db_dir} Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯")
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ú¯Ø± ÙØ§ÛŒÙ„ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
            if os.path.exists(db_path):
                print(f"ğŸ“ ÙØ§ÛŒÙ„ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø§Ø² Ù‚Ø¨Ù„ Ø¯Ø± {db_path} ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯")
            else:
                # Ø§ÛŒØ¬Ø§Ø¯ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø®Ø§Ù„ÛŒ
                try:
                    import sqlite3
                    conn = sqlite3.connect(db_path)
                    conn.close()
                    print(f"âœ… ÙØ§ÛŒÙ„ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ SQLite Ø¯Ø± {db_path} Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯")
                except Exception as e:
                    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡: {e}")
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ø¬Ø¯Ø§ÙˆÙ„ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡
    try:
        print("Ø§ÛŒØ¬Ø§Ø¯ Ø¬Ø¯Ø§ÙˆÙ„ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡...")
        from findataanalyzer.utils.database import DatabaseManager
        db_manager = DatabaseManager(config.get("database", {}))
        print("âœ… Ø¬Ø¯Ø§ÙˆÙ„ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù†Ø¯")
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø¬Ø¯Ø§ÙˆÙ„ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡: {e}")


def install_dependencies(gpu_support=False):
    """Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ."""
    print("Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ...")
    
    # Ù„ÛŒØ³Øª ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡
    base_packages = [
        "numpy",
        "pandas",
        "scipy",
        "matplotlib",
        "scikit-learn",
        "pyyaml",
        "tqdm",
        "requests",
        "schedule",
        "sqlalchemy",
        "fastapi",
        "uvicorn",
        "python-multipart",
        "pillow",
        "opencv-python"
    ]
    
    # ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ GPU
    gpu_packages = [
        "tensorflow",
        "tensorboard"
    ]
    
    # Ø§Ù†ØªØ®Ø§Ø¨ Ù„ÛŒØ³Øª Ù†Ù‡Ø§ÛŒÛŒ
    packages = base_packages
    if gpu_support:
        packages.extend(gpu_packages)
    
    # Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§
    try:
        print(f"Ù†ØµØ¨ {len(packages)} Ù¾Ú©ÛŒØ¬...")
        cmd = [sys.executable, "-m", "pip", "install", "--upgrade"] + packages
        process = subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        print("âœ… ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù†ØµØ¨ Ø´Ø¯Ù†Ø¯")
    except subprocess.CalledProcessError as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§: {e}")
        if e.stderr:
            print(f"Ø®Ø·Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ: {e.stderr.decode('utf-8')}")


def copy_default_config():
    """Ú©Ù¾ÛŒ ÙØ§ÛŒÙ„ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶."""
    print("Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ ÙØ§ÛŒÙ„ ØªÙ†Ø¸ÛŒÙ…Ø§Øª...")
    
    config_path = Path("configs/settings.yaml")
    default_config_path = Path(__file__).parent / "default_settings.yaml"
    
    if not config_path.exists():
        config_path.parent.mkdir(parents=True, exist_ok=True)
        
        if default_config_path.exists():
            shutil.copy(default_config_path, config_path)
            print(f"âœ… ÙØ§ÛŒÙ„ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¯Ø± {config_path} Ú©Ù¾ÛŒ Ø´Ø¯")
        else:
            # Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶
            default_config = {
                "gpu": {
                    "enabled": False,
                    "device": "cuda:0",
                    "memory_fraction": 0.8,
                    "allow_growth": True
                },
                "server": {
                    "host": "0.0.0.0",
                    "port": 8000,
                    "workers": 4,
                    "timeout": 300,
                    "max_requests": 1000
                },
                "database": {
                    "url": "sqlite:///data/findataanalyzer.db",
                    "pool_size": 5,
                    "pool_recycle": 3600
                },
                "data_pipeline": {
                    "raw_data_dir": "data/raw",
                    "processed_data_dir": "data/processed",
                    "cache_dir": "data/cache",
                    "batch_size": 32,
                    "num_workers": 4
                },
                "experiment_tracking": {
                    "enabled": True,
                    "backend": "sqlite",
                    "experiments_dir": "experiments",
                    "metrics_dir": "experiments/metrics",
                    "checkpoints_dir": "experiments/checkpoints",
                    "tensorboard_dir": "experiments/tensorboard"
                },
                "logging": {
                    "level": "INFO",
                    "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
                    "file": "logs/findataanalyzer.log",
                    "max_bytes": 10485760,
                    "backup_count": 5
                },
                "model": {
                    "input_size": [224, 224],
                    "batch_size": 32,
                    "learning_rate": 0.001,
                    "epochs": 100,
                    "early_stopping_patience": 10,
                    "val_split": 0.15,
                    "test_split": 0.15,
                    "models_dir": "models",
                    "checkpoints_dir": "models/checkpoints"
                }
            }
            
            with open(config_path, "w") as f:
                yaml.dump(default_config, f, default_flow_style=False)
            print(f"âœ… ÙØ§ÛŒÙ„ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¯Ø± {config_path} Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯")
    else:
        print(f"ğŸ“ ÙØ§ÛŒÙ„ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¯Ø± {config_path} Ø§Ø² Ù‚Ø¨Ù„ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯")


def update_config_with_gpu(config_path, gpu_enabled):
    """Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª GPU Ø¯Ø± ÙØ§ÛŒÙ„ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ."""
    if not os.path.exists(config_path):
        print(f"âŒ ÙØ§ÛŒÙ„ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¯Ø± {config_path} ÛŒØ§ÙØª Ù†Ø´Ø¯")
        return
    
    try:
        with open(config_path, "r") as f:
            config = yaml.safe_load(f)
        
        if "gpu" not in config:
            config["gpu"] = {}
        
        config["gpu"]["enabled"] = gpu_enabled
        
        with open(config_path, "w") as f:
            yaml.dump(config, f, default_flow_style=False)
        
        print(f"âœ… ØªÙ†Ø¸ÛŒÙ…Ø§Øª GPU Ø¯Ø± ÙØ§ÛŒÙ„ {config_path} Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø´Ø¯")
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª GPU: {e}")


def start_api_server(config):
    """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÙˆØ± API."""
    print("Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÙˆØ± API...")
    
    host = config.get("server.host", "0.0.0.0")
    port = config.get("server.port", 8000)
    workers = config.get("server.workers", 4)
    
    try:
        cmd = [
            sys.executable, "-m", "uvicorn", 
            "findataanalyzer.api.main:app", 
            "--host", host, 
            "--port", str(port),
            "--workers", str(workers)
        ]
        
        print(f"Ø¯Ø± Ø­Ø§Ù„ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÙˆØ± API Ø¯Ø± http://{host}:{port}")
        process = subprocess.Popen(cmd)
        
        # Ú©Ù…ÛŒ ØµØ¨Ø± Ú©Ù†ÛŒÙ… ØªØ§ Ø³Ø±ÙˆØ± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´ÙˆØ¯
        time.sleep(2)
        
        if process.poll() is None:
            print(f"âœ… Ø³Ø±ÙˆØ± API Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø± http://{host}:{port} Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯")
            return process
        else:
            print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÙˆØ± API")
            return None
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÙˆØ± API: {e}")
        return None


def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ."""
    args = parse_args()
    
    print("=" * 60)
    print(" Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÙˆØ± Ù…Ø­Ø§Ø³Ø¨Ø§ØªÛŒ FinDataAnalyzer ")
    print("=" * 60)
    
    # Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ ØªÙ†Ø¸ÛŒÙ…Ø§Øª
    copy_default_config()
    
    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª
    config_manager = ConfigManager(args.config)
    
    # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª GPU
    if args.gpu:
        gpu_supported = check_gpu_support()
        update_config_with_gpu(args.config, gpu_supported)
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒâ€ŒÙ‡Ø§
    if args.setup_dirs:
        setup_directories(config_manager.get_all())
    
    # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡
    if args.setup_db:
        setup_database(config_manager.get_all())
    
    # Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§
    if args.install_deps:
        install_dependencies(args.gpu)
    
    # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ LogManager
    log_config = config_manager.get("logging", {})
    log_manager = LogManager({"logging": log_config})
    logger = log_manager.get_logger()
    
    # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÙˆØ± API (ÙÙ‚Ø· Ø¯Ø± Ù…Ø­ÛŒØ· ØªÙˆÙ„ÛŒØ¯)
    if args.env == "prod":
        api_server = start_api_server(config_manager.get_all())
    
    logger.info("Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÙˆØ± Ù…Ø­Ø§Ø³Ø¨Ø§ØªÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯")
    print("\nâœ… Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÙˆØ± Ù…Ø­Ø§Ø³Ø¨Ø§ØªÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯")


if __name__ == "__main__":
    main() 